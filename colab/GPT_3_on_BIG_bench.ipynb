{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zYbxhDRWQqh"
      },
      "source": [
        "# Motivation\n",
        "\n",
        "BIG-Bench, the largest modern language-model benchmark, does not provide example code for evaluating OpenAI GPT-3 models. This notebook implements a barebones example of doing just that on any of 200+ BIG-Bench tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6K9l4VSIZnl"
      },
      "source": [
        "## BIG-Bench Metrics\n",
        "\n",
        "Each task can support multiple metrics, but has one preferred metric, used for aggregate scores. The full list of available metrics for JSON tasks can be found on the [BIG-bench repo](https://github.com/google/BIG-bench/blob/main/docs/doc.md#available-metrics). Programmatic tasks can define their own metrics. The main JSON metrics are:\n",
        "\n",
        "Text-to-text:\n",
        "- `exact_string_match`\n",
        "- `bleu`\n",
        "- `bleurt`: uses BERT to judge similarity\n",
        "- `rouge`\n",
        "\n",
        "Multiple-choice:\n",
        "- `multiple_choice_grade`: A weighted multiple choice accuracy between 0-100, where a set of\n",
        "targets and scores for each potential target are specified. This reduces to standard multiple\n",
        "choice accuracy when a single target is assigned a score of 1 and the rest score 0.\n",
        "- `expected_calibration_error`: A measure of a model’s calibration – i.e. how well the model’s\n",
        "accuracy matches the probability it assigns to a response. expected_calibration_error is the\n",
        "absolute deviation between the assigned probability and average accuracy, after binning\n",
        "examples in terms of assigned probability (Naeini et al., 2015).\n",
        "- `multiple_choice_brier_score`: A measure of calibration given as the squared error between\n",
        "model assigned probabilities and 0, 1 targets across classes (Brier, 1950)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nb09vv0V7Yg"
      },
      "source": [
        "## Install BIG-Bench\n",
        "\n",
        "This takes a bit of time so you could probably go make tea and scroll through a few FTX Twitter threads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGgm7BldUzGQ",
        "outputId": "e7e21236-012f-43bf-9078-15f373d7ba01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/google/BIG-bench.git\n",
            "  Cloning https://github.com/google/BIG-bench.git to /tmp/pip-req-build-6v_2nxjk\n",
            "  Running command git clone -q https://github.com/google/BIG-bench.git /tmp/pip-req-build-6v_2nxjk\n",
            "Processing //tmp/pip-req-build-6v_2nxjk/bleurt/bleurt-b610120347ef22b494b6d69b4316e303f5932516.zip\n",
            "Collecting tensorflow-text>=2.6\n",
            "  Downloading tensorflow_text-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.6 in /usr/local/lib/python3.7/dist-packages (from bigbench==0.0.1) (2.9.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from bigbench==0.0.1) (1.3.0)\n",
            "Collecting black>=21.6b0\n",
            "  Downloading black-22.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 53.7 MB/s \n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.6.1-py3-none-any.whl (441 kB)\n",
            "\u001b[K     |████████████████████████████████| 441 kB 54.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from bigbench==0.0.1) (0.5.3)\n",
            "Collecting immutabledict\n",
            "  Downloading immutabledict-2.2.3-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bigbench==0.0.1) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.7/dist-packages (from bigbench==0.0.1) (1.21.6)\n",
            "Collecting pytest>=6.2.4\n",
            "  Downloading pytest-7.2.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 68.5 MB/s \n",
            "\u001b[?25hCollecting requests-unixsocket>=0.2.0\n",
            "  Downloading requests_unixsocket-0.3.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting RestrictedPython>=5.1\n",
            "  Downloading RestrictedPython-6.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from bigbench==0.0.1) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from bigbench==0.0.1) (1.7.3)\n",
            "Requirement already satisfied: seaborn>=0.11.2 in /usr/local/lib/python3.7/dist-packages (from bigbench==0.0.1) (0.11.2)\n",
            "Collecting t5>=0.9.1\n",
            "  Downloading t5-0.9.3-py3-none-any.whl (153 kB)\n",
            "\u001b[K     |████████████████████████████████| 153 kB 73.9 MB/s \n",
            "\u001b[?25hCollecting seqio>=0.0.6\n",
            "  Downloading seqio-0.0.12-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 69.3 MB/s \n",
            "\u001b[?25hCollecting transformers>=4.12.5\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 46.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from bleurt@ file://localhost//tmp/pip-req-build-6v_2nxjk/bleurt/bleurt-b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt->bigbench==0.0.1) (1.3.5)\n",
            "Collecting tf-slim>=1.1\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 75.2 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 60.7 MB/s \n",
            "\u001b[?25hCollecting pathspec>=0.9.0\n",
            "  Downloading pathspec-0.10.2-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from black>=21.6b0->bigbench==0.0.1) (2.0.1)\n",
            "Collecting click>=8.0.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting platformdirs>=2\n",
            "  Downloading platformdirs-2.5.4-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from black>=21.6b0->bigbench==0.0.1) (4.1.1)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Collecting typed-ast>=1.4.2\n",
            "  Downloading typed_ast-1.5.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 67.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click>=8.0.0->black>=21.6b0->bigbench==0.0.1) (4.13.0)\n",
            "Collecting exceptiongroup>=1.0.0rc8\n",
            "  Downloading exceptiongroup-1.0.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.4->bigbench==0.0.1) (21.3)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.4->bigbench==0.0.1) (22.1.0)\n",
            "Collecting pluggy<2.0,>=0.12\n",
            "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting iniconfig\n",
            "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click>=8.0.0->black>=21.6b0->bigbench==0.0.1) (3.10.0)\n",
            "Requirement already satisfied: requests>=1.1 in /usr/local/lib/python3.7/dist-packages (from requests-unixsocket>=0.2.0->bigbench==0.0.1) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=1.1->requests-unixsocket>=0.2.0->bigbench==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.1->requests-unixsocket>=0.2.0->bigbench==0.0.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.1->requests-unixsocket>=0.2.0->bigbench==0.0.1) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.1->requests-unixsocket>=0.2.0->bigbench==0.0.1) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->bigbench==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->bigbench==0.0.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bigbench==0.0.1) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bigbench==0.0.1) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bigbench==0.0.1) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bigbench==0.0.1) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->bleurt@ file://localhost//tmp/pip-req-build-6v_2nxjk/bleurt/bleurt-b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt->bigbench==0.0.1) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->bigbench==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.7/dist-packages (from seqio>=0.0.6->bigbench==0.0.1) (0.3.22+cuda11.cudnn805)\n",
            "Collecting clu\n",
            "  Downloading clu-0.0.7-py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 1.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (from seqio>=0.0.6->bigbench==0.0.1) (0.3.23)\n",
            "Collecting tfds-nightly\n",
            "  Downloading tfds_nightly-4.7.0.dev202211140046-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 56.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from t5>=0.9.1->bigbench==0.0.1) (3.7)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from t5>=0.9.1->bigbench==0.0.1) (0.5.0)\n",
            "Collecting mesh-tensorflow[transformer]>=0.1.13\n",
            "  Downloading mesh_tensorflow-0.1.21-py3-none-any.whl (385 kB)\n",
            "\u001b[K     |████████████████████████████████| 385 kB 74.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from t5>=0.9.1->bigbench==0.0.1) (2.11.0)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from t5>=0.9.1->bigbench==0.0.1) (1.12.1+cu113)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 46.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5>=0.9.1->bigbench==0.0.1) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5>=0.9.1->bigbench==0.0.1) (4.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (2.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (1.50.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (2.9.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (2.9.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (2.9.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (0.27.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (14.0.6)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (57.4.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (1.12)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.6->bigbench==0.0.1) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.6->bigbench==0.0.1) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.6->bigbench==0.0.1) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.6->bigbench==0.0.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.6->bigbench==0.0.1) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.6->bigbench==0.0.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.6->bigbench==0.0.1) (2.14.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.6->bigbench==0.0.1) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.6->bigbench==0.0.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.6->bigbench==0.0.1) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.6->bigbench==0.0.1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.6->bigbench==0.0.1) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.6->bigbench==0.0.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.6->bigbench==0.0.1) (3.2.2)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text>=2.6->bigbench==0.0.1) (0.12.0)\n",
            "Collecting tensorflow>=2.6\n",
            "  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.0 MB 15 kB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-text to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-text>=2.6\n",
            "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 51.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 74.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.5->bigbench==0.0.1) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.5->bigbench==0.0.1) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.5->bigbench==0.0.1) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 53.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.5->bigbench==0.0.1) (3.8.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from clu->seqio>=0.0.6->bigbench==0.0.1) (0.9.0)\n",
            "Collecting ml-collections\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting flax\n",
            "  Downloading flax-0.6.1-py3-none-any.whl (185 kB)\n",
            "\u001b[K     |████████████████████████████████| 185 kB 71.9 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 77.3 MB/s \n",
            "\u001b[?25hCollecting dill<0.3.6\n",
            "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[K     |████████████████████████████████| 95 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->bigbench==0.0.1) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets->bigbench==0.0.1) (2022.10.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 73.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets->bigbench==0.0.1) (3.8.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (2.1.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (6.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (1.8.1)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 68.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->clu->seqio>=0.0.6->bigbench==0.0.1) (5.10.0)\n",
            "Collecting optax\n",
            "  Downloading optax-0.1.3-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 64.0 MB/s \n",
            "\u001b[?25hCollecting rich>=11.1\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 70.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax->clu->seqio>=0.0.6->bigbench==0.0.1) (1.0.4)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=11.1->flax->clu->seqio>=0.0.6->bigbench==0.0.1) (2.6.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from ml-collections->clu->seqio>=0.0.6->bigbench==0.0.1) (0.5.5)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 72.1 MB/s \n",
            "\u001b[?25hCollecting chex>=0.0.4\n",
            "  Downloading chex-0.1.5-py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax->clu->seqio>=0.0.6->bigbench==0.0.1) (0.1.7)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax->clu->seqio>=0.0.6->bigbench==0.0.1) (0.12.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->t5>=0.9.1->bigbench==0.0.1) (0.8.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from sacrebleu->t5>=0.9.1->bigbench==0.0.1) (4.9.1)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5>=0.9.1->bigbench==0.0.1) (0.10.2)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5>=0.9.1->bigbench==0.0.1) (1.10.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5>=0.9.1->bigbench==0.0.1) (2.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5>=0.9.1->bigbench==0.0.1) (1.56.4)\n",
            "Building wheels for collected packages: bigbench, bleurt, ml-collections, rouge-score\n",
            "  Building wheel for bigbench (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bigbench: filename=bigbench-0.0.1-py3-none-any.whl size=366182272 sha256=5cde9ce42dd9037a20b711e2dcdd99d836d985c6867a1de54e85d49779f89b2a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ifsl1w73/wheels/1d/f9/96/a916aef7eed64567a302c408003c04da1b46b294dad4fc0607\n",
            "  Building wheel for bleurt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bleurt: filename=BLEURT-0.0.2-py3-none-any.whl size=16454023 sha256=a553409ecb399258cdf19e3180d9130a3010d67c91c23f339d4ca0eda86a69fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/69/fe/704157a81713d07aeb2f82ebb33ddb88762878f011953b3564\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94524 sha256=a9260c8e79facdcc7f7df11c210393bc6d9e0a6334a9011e28734dd2cfc7f9b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/da/64/33c926a1b10ff19791081b705879561b715a8341a856a3bbd2\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=7cca367538af2b6ff1fdcc48246b0cbd152e4187d750459c1712951748fd056f\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ac/6b/38096e3c5bf1dc87911e3585875e21a3ac610348e740409c76\n",
            "Successfully built bigbench bleurt ml-collections rouge-score\n",
            "Installing collected packages: urllib3, commonmark, chex, rich, optax, dill, ml-collections, flax, click, tokenizers, tfds-nightly, tensorflow-text, sentencepiece, portalocker, mesh-tensorflow, huggingface-hub, colorama, clu, xxhash, typed-ast, transformers, tf-slim, seqio, sacrebleu, rouge-score, responses, pluggy, platformdirs, pathspec, mypy-extensions, multiprocess, iniconfig, exceptiongroup, t5, RestrictedPython, requests-unixsocket, pytest, immutabledict, datasets, bleurt, black, bigbench\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\u001b[0m\n",
            "Successfully installed RestrictedPython-6.0 bigbench-0.0.1 black-22.10.0 bleurt-0.0.2 chex-0.1.5 click-8.1.3 clu-0.0.7 colorama-0.4.6 commonmark-0.9.1 datasets-2.6.1 dill-0.3.5.1 exceptiongroup-1.0.3 flax-0.6.1 huggingface-hub-0.10.1 immutabledict-2.2.3 iniconfig-1.1.1 mesh-tensorflow-0.1.21 ml-collections-0.1.1 multiprocess-0.70.13 mypy-extensions-0.4.3 optax-0.1.3 pathspec-0.10.2 platformdirs-2.5.4 pluggy-1.0.0 portalocker-2.6.0 pytest-7.2.0 requests-unixsocket-0.3.0 responses-0.18.0 rich-12.6.0 rouge-score-0.1.2 sacrebleu-2.3.1 sentencepiece-0.1.97 seqio-0.0.12 t5-0.9.3 tensorflow-text-2.9.0 tf-slim-1.1.0 tfds-nightly-4.7.0.dev202211140046 tokenizers-0.13.2 transformers-4.24.0 typed-ast-1.5.4 urllib3-1.25.11 xxhash-3.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 2.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.2.0.62-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from openai) (4.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2022.9.24)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=57cb4d1c90e9640dfaea6f3c9d7de1b9f572bdc75b681c505522976dee6ef48d\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/de/db/e82770b480ec30fd4a6d67108744b9c52be167c04fcf4af7b5\n",
            "Successfully built openai\n",
            "Installing collected packages: pandas-stubs, openai\n",
            "Successfully installed openai-0.25.0 pandas-stubs-1.2.0.62\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/google/BIG-bench.git\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aNI-wwOV4Hv"
      },
      "source": [
        "## Running\n",
        "You'll need to provide an [OpenAI API key](https://openai.com/blog/api-no-waitlist/) in the input field below (appears after you run the cell)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6EXVE5tDrc6",
        "outputId": "1f46ef89-2f81-467b-c691-e3728eccb9d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter token here:··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = getpass('Enter token here:') # should look like `sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4XwncouZU8Un"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import importlib\n",
        "import pprint as pp\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "\n",
        "import openai\n",
        "import bigbench.models.model_utils as model_utils\n",
        "import bigbench.api.json_task as json_task\n",
        "import bigbench.api.results as results_api\n",
        "import bigbench.api.util as util\n",
        "import bigbench.models.huggingface_models as hf_models\n",
        "from bigbench.evaluate_task import _sanitize_results\n",
        "from bigbench.api.model import Model, ModelData\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0kUMJ8fVQAz"
      },
      "outputs": [],
      "source": [
        "# from inverse-scaling-eval-pipeline\n",
        "size_dict = {\n",
        "    # based on https://blog.eleuther.ai/gpt3-model-sizes/\n",
        "    \"ada\": 350_000_000,\n",
        "    \"babbage\": 1_300_000_000,\n",
        "    \"curie\": 6_700_000_000,\n",
        "    \"davinci\": 175_000_000_000,\n",
        "    \"text-ada-001\": 350_000_000,\n",
        "    \"text-babbage-001\": 1_300_000_000,\n",
        "    \"text-curie-001\": 6_700_000_000,\n",
        "    \"text-davinci-001\": 175_000_000_000,\n",
        "    \"text-davinci-002\": 175_000_000_000,\n",
        "}\n",
        "\n",
        "class OpenAIGPT3(Model):\n",
        "    def __init__(self, model='ada', max_parallel=20):\n",
        "        self.queries = []\n",
        "        self.model = model\n",
        "        self.max_parallel = max_parallel\n",
        "\n",
        "    def generate_text(\n",
        "        self, inputs, max_length=500, stop_string=None, output_regex=None,\n",
        "    ):\n",
        "        if isinstance(inputs, str):\n",
        "            inputs = [inputs]\n",
        "        outputs = []\n",
        "\n",
        "        n_batches = int(np.ceil(len(inputs) / self.max_parallel))\n",
        "        for batch_idx in range(n_batches):\n",
        "            batch_inputs = inputs[\n",
        "                batch_idx * self.max_parallel : (batch_idx + 1) * self.max_parallel\n",
        "            ]\n",
        "            batch_outputs = openai.Completion.create(\n",
        "                model=self.model,\n",
        "                prompt=batch_inputs,\n",
        "                max_tokens=max_length,\n",
        "                stop=stop_string,\n",
        "                temperature=0,\n",
        "            )\n",
        "            for completion in batch_outputs.choices:\n",
        "                outputs.append(completion.text)\n",
        "\n",
        "        if len(inputs) == 1:\n",
        "            outputs = outputs[0]\n",
        "        \n",
        "        outputs = model_utils.postprocess_output(\n",
        "            outputs, max_length, stop_string, output_regex\n",
        "        )\n",
        "        return outputs\n",
        "\n",
        "    def flatten_multiple_choice_examples(self, inputs, targets):\n",
        "        flat_idx = []\n",
        "        flat_inputs = []\n",
        "        flat_choices = []\n",
        "        for example_id, (example_input, choices) in enumerate(zip(inputs, targets)):\n",
        "            for choice_id, choice in enumerate(choices):\n",
        "                flat_idx.append((example_id, choice_id))\n",
        "                flat_inputs.append(example_input)\n",
        "                flat_choices.append(choice)\n",
        "\n",
        "        return flat_idx, flat_inputs, flat_choices\n",
        "\n",
        "    def get_target_logprobs(self, completion, target):\n",
        "        '''Naive implementation of getting the logprobs of the target:\n",
        "        \n",
        "        To find out which tokens the target is made of, the function iteratively \n",
        "        concatenates returned tokens from the end, and compares a running \n",
        "        concatenation with the target.\n",
        "        '''\n",
        "        cum_sum = ''\n",
        "        for i, token in enumerate(reversed(completion.logprobs['tokens'])):\n",
        "            cum_sum = token + cum_sum\n",
        "            if cum_sum.strip() == target.strip():\n",
        "                break\n",
        "\n",
        "        target_tokens_logprobs = completion.logprobs['token_logprobs'][-(i+1):]\n",
        "        if None in target_tokens_logprobs:\n",
        "            print('Found None in target_tokens_logprobs:', target_tokens_logprobs, 'in completion:', completion)\n",
        "        return sum(target_tokens_logprobs)\n",
        "\n",
        "    def cond_log_prob(self, inputs, targets, absolute_normalization=False):\n",
        "\n",
        "        if isinstance(targets, str):\n",
        "            targets = [targets]\n",
        "\n",
        "        if isinstance(inputs, str):\n",
        "            inputs = [inputs]\n",
        "            targets = [targets]\n",
        "\n",
        "        flat_idx, flat_inputs, flat_choices = self.flatten_multiple_choice_examples(\n",
        "            inputs=inputs, targets=targets\n",
        "        )\n",
        "        num_examples = len(flat_idx)\n",
        "        flat_scores = []\n",
        "        batch_size = self.max_parallel\n",
        "        for idx in range(0, num_examples, batch_size):\n",
        "            batch_idx = flat_idx[idx : min(idx + batch_size, num_examples)]\n",
        "            batch_inputs = flat_inputs[idx : min(idx + batch_size, num_examples)]\n",
        "            batch_choices = flat_choices[idx : min(idx + batch_size, num_examples)]\n",
        "\n",
        "            batch_queries = [inpt + target for inpt, target in zip(batch_inputs, batch_choices)]\n",
        "            batch_outputs = openai.Completion.create(\n",
        "                model=self.model,\n",
        "                prompt=batch_queries,\n",
        "                max_tokens=0,\n",
        "                temperature=0,\n",
        "                logprobs=1,\n",
        "                echo=True,\n",
        "            )\n",
        "\n",
        "            for i, completion in enumerate(batch_outputs.choices):\n",
        "                target_logprobs = self.get_target_logprobs(completion, batch_choices[i])\n",
        "                flat_scores.append(target_logprobs)\n",
        "\n",
        "        scores = [[] for _ in range(len(inputs))]\n",
        "\n",
        "        for idx, score in zip(flat_idx, flat_scores):\n",
        "            if score == 0:\n",
        "              # all tokens were masked. Setting score to -inf.\n",
        "              print('Found score identical to zero. Probably from empty target. '\n",
        "                             'Setting score to -inf.'\n",
        "                            )\n",
        "              scores[idx[0]].append(-np.inf)\n",
        "            else:\n",
        "              scores[idx[0]].append(score)\n",
        "\n",
        "        if not absolute_normalization:\n",
        "            scores = [\n",
        "                list(score_row - scipy.special.logsumexp(score_row))\n",
        "                for score_row in scores\n",
        "            ]\n",
        "\n",
        "        if len(inputs) == 1:\n",
        "            scores = scores[0]\n",
        "\n",
        "        return scores\n",
        "\n",
        "    def model_data(self):\n",
        "        # TODO: replace with correct metadata\n",
        "        return ModelData(\n",
        "            model_family=\"GPT-3\",\n",
        "            model_name=self.model,\n",
        "            total_params=size_dict[self.model],\n",
        "            non_embedding_params=size_dict[self.model], # don't know\n",
        "            flop_matched_non_embedding_params=size_dict[self.model], # don't know\n",
        "            training_batch_size=1, # don't know\n",
        "            training_steps=100_000_000, # don't know\n",
        "            decoding_params={},\n",
        "            description=\"see https://arxiv.org/abs/2005.14165\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTG1ar2vVRub"
      },
      "outputs": [],
      "source": [
        "def evaluate_on_task(task_name, model_name, huggface=False, max_examples=None, shots_list=[0,1,2,3]):\n",
        "    '''Also supports gpt2 models from huggingface.'''\n",
        "\n",
        "    task_module_name = f\"bigbench.benchmark_tasks.{task_name}\"\n",
        "    task_module = importlib.import_module(task_module_name)\n",
        "    task_submodule_name = f\"{task_module_name}.task\"\n",
        "\n",
        "    module_path = list(task_module.__path__)[0]\n",
        "    json_path = os.path.join(module_path, \"task.json\")\n",
        "\n",
        "    if os.path.exists(json_path):\n",
        "        task = json_task.JsonTask(\n",
        "            json_path,\n",
        "            max_examples=max_examples,\n",
        "            shot_list=list(map(int, shots_list)),\n",
        "        )\n",
        "    else:\n",
        "        task = util.load_programmatic_task(task_submodule_name)\n",
        "\n",
        "    model = None\n",
        "    if huggface:\n",
        "        model = hf_models.BIGBenchHFModel(\n",
        "                model_name=model_name,\n",
        "                max_length=1000,\n",
        "                show_progress=False,\n",
        "        )\n",
        "    else:\n",
        "        model = OpenAIGPT3(model_name)\n",
        "\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"evaluating {model_name}...\")\n",
        "\n",
        "    results = task.evaluate_model(model, max_examples=max_examples)\n",
        "\n",
        "    if isinstance(results, list):\n",
        "        results_list = results\n",
        "    else:\n",
        "        results_list = [results]\n",
        "\n",
        "    results_list = _sanitize_results(scores=results_list)\n",
        "    results_list = results_api.add_aggregate_scores(\n",
        "        task_name=task_name, scores=results_list\n",
        "    )\n",
        "\n",
        "    print(f\"results:\")\n",
        "    for r in results_list:\n",
        "        print(f\"{pp.pformat(r.score_dict)}\")\n",
        "\n",
        "\n",
        "    return results_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxzKRLDAVaE-",
        "outputId": "a684ba7c-5606-4366-c909-a4d092f47495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "evaluating text-curie-001...\n",
            "evaluating analytic_entailment for 3 shots...\n",
            "results:\n",
            "{'calibration_multiple_choice_brier_score': 0.49853687789680134,\n",
            " 'expected_calibration_error': 0.49579620574939887,\n",
            " 'multiple_choice_grade': 0.4857142857142857,\n",
            " 'normalized_aggregate_score': -2.857142857142858}\n"
          ]
        }
      ],
      "source": [
        "results_data = evaluate_on_task(task_name='analytic_entailment', model_name='text-curie-001', shots_list=[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2SGHi3HVnCx",
        "outputId": "f7b8e3af-3082-4ca2-ef92-8db888b4cc61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "evaluating text-curie-001...\n",
            "evaluating emoji_movie for 3 shots...\n",
            "results:\n",
            "{'bleu': 10.839884430478508,\n",
            " 'calibration_multiple_choice_brier_score': 0.22352366663024548,\n",
            " 'exact_str_match': 0.08,\n",
            " 'expected_calibration_error': 0.4583487377784708,\n",
            " 'multiple_choice_grade': 0.2,\n",
            " 'normalized_aggregate_score': 4.857225732735058e-14,\n",
            " 'rouge1': 19.274314574314577,\n",
            " 'rouge2': 11.933333333333332,\n",
            " 'rougeLsum': 19.346176046176044}\n"
          ]
        }
      ],
      "source": [
        "results_data = evaluate_on_task(task_name='emoji_movie', model_name='text-curie-001', shots_list=[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMHVzNszcIef",
        "outputId": "5f375838-5f6e-4eb3-90d7-28b663ecbf5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "evaluating ada...\n",
            "results:\n",
            "{'first_response_score': -0.97,\n",
            " 'full': -0.954387807683251,\n",
            " 'second_response_score': 0.015612192316749042}\n",
            "{'first_response_score': -0.97,\n",
            " 'full': -0.954387807683251,\n",
            " 'normalized_aggregate_score': 67.42686987194583,\n",
            " 'second_response_score': 0.015612192316749042}\n"
          ]
        }
      ],
      "source": [
        "results_data = evaluate_on_task(task_name='taboo', model_name='ada', shots_list=[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TvH9yLGdQ_1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
