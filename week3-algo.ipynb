{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-digit XOR in binary\n",
    "\n",
    "Logical XOR is a binary operation that takes two bits and returns 1 if they are different and 0 if they are the same. \n",
    "\n",
    "For example, 0 XOR 0 = 0, 0 XOR 1 = 1, 1 XOR 0 = 1, and 1 XOR 1 = 0.\n",
    "\n",
    "Here, I construct a dataset by generating 2-digit numbers, computing their XOR result, and representing everything in binary (zero-padded to 7 bits).\n",
    "\n",
    "E.g. for 3 XOR 25, the result is 26:\n",
    "    \n",
    "    Prompt: '0000011 XOR 0011001 ='. Completion: ' 0011010'\n",
    "\n",
    "\n",
    "UPD. The above formatting resulted in 97% accuracy after fine-tuning. I then remembered about BPE and changed it to the following:\n",
    "\n",
    "    Prompt: '0 0 0 0 0 1 1 XOR 0 0 1 1 0 0 1 ='. Completion: ' 0 0 1 1 0 1 0'\n",
    "\n",
    "This resulted in 100% accuracy after fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 4851\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def bin_string_from_int(n, length=7):\n",
    "    return ' '.join(list(bin(n)[2:].zfill(length)))\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for i in range(1, 99):\n",
    "    for j in range(1, 100-i):\n",
    "        dataset.append((f'{bin_string_from_int(i)} XOR {bin_string_from_int(j)} =', f' {bin_string_from_int(i^j)}'))\n",
    "\n",
    "np.random.shuffle(dataset)\n",
    "print('dataset size:', len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 4000\n",
      "test set size: 851\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_set = dataset[:-851]\n",
    "test_set = dataset[-851:]\n",
    "\n",
    "print('train set size:', len(train_set))\n",
    "print('test set size:', len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_n_shot(dataset, n=1):\n",
    "    examples = [''.join([question, answer]) for question, answer in dataset[:n]]\n",
    "    dataset = [('\\n'.join(examples) + '\\n' + question, answer) for question, answer in dataset[n:]]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 0 1 1 0 1 0 XOR 0 1 1 0 1 1 1 = 0 1 0 1 1 0 1\n",
      "0 0 0 0 1 0 1 XOR 0 1 0 0 0 1 0 = 0 1 0 0 1 1 1\n",
      "0 0 0 1 0 1 0 XOR 1 0 0 1 1 0 1 = 1 0 0 0 1 1 1\n",
      "0 0 0 1 1 1 0 XOR 0 1 1 1 0 1 1 =\n",
      "\n",
      "0 0 1 1 0 1 0 XOR 0 1 1 0 1 1 1 = 0 1 0 1 1 0 1\n",
      "0 0 0 0 1 0 1 XOR 0 1 0 0 0 1 0 = 0 1 0 0 1 1 1\n",
      "0 0 0 1 0 1 0 XOR 1 0 0 1 1 0 1 = 1 0 0 0 1 1 1\n",
      "0 0 0 0 1 0 1 XOR 1 0 1 1 1 0 0 =\n",
      "\n",
      "0 0 1 1 0 1 0 XOR 0 1 1 0 1 1 1 = 0 1 0 1 1 0 1\n",
      "0 0 0 0 1 0 1 XOR 0 1 0 0 0 1 0 = 0 1 0 0 1 1 1\n",
      "0 0 0 1 0 1 0 XOR 1 0 0 1 1 0 1 = 1 0 0 0 1 1 1\n",
      "0 0 1 1 0 0 0 XOR 0 1 0 0 0 1 1 =\n"
     ]
    }
   ],
   "source": [
    "for question, answer in with_n_shot(test_set, n=3)[:3]:\n",
    "    print()\n",
    "    print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0 0 1 1 0 1 0 XOR 0 1 1 0 1 1 1 =', ' 0 1 0 1 1 0 1'),\n",
       " ('0 0 0 0 1 0 1 XOR 0 1 0 0 0 1 0 =', ' 0 1 0 0 1 1 1'),\n",
       " ('0 0 0 1 0 1 0 XOR 1 0 0 1 1 0 1 =', ' 1 0 0 0 1 1 1'),\n",
       " ('0 0 0 1 1 1 0 XOR 0 1 1 1 0 1 1 =', ' 0 1 1 0 1 0 1'),\n",
       " ('0 0 0 0 1 0 1 XOR 1 0 1 1 1 0 0 =', ' 1 0 1 1 0 0 1'),\n",
       " ('0 0 1 1 0 0 0 XOR 0 1 0 0 0 1 1 =', ' 0 1 1 1 0 1 1'),\n",
       " ('1 0 0 0 0 0 1 XOR 0 0 0 1 0 0 0 =', ' 1 0 0 1 0 0 1'),\n",
       " ('0 0 1 0 1 0 0 XOR 0 0 0 0 0 1 0 =', ' 0 0 1 0 1 1 0'),\n",
       " ('0 1 1 1 1 1 0 XOR 0 1 0 0 0 0 0 =', ' 0 0 1 1 1 1 0'),\n",
       " ('0 1 1 1 1 1 0 XOR 0 0 1 1 0 1 0 =', ' 0 1 0 0 1 0 0')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 06:13:22.368454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/nikita/miniconda3/envs/alm/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.openai_bb import OpenAIGPT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAIGPT3('curie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "questions, answers = zip(*test_set)\n",
    "\n",
    "outputs = model.generate_text(questions, max_length=20, stop_string='\\n')\n",
    "\n",
    "correct_ones = np.array(outputs) == np.array(answers)\n",
    "print('accuracy:', correct_ones.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.010588235294117647\n"
     ]
    }
   ],
   "source": [
    "# 1-shot\n",
    "questions, answers = zip(*with_n_shot(test_set, n=1))\n",
    "\n",
    "outputs = model.generate_text(questions, max_length=20, stop_string='\\n')\n",
    "\n",
    "correct_ones = np.array(outputs) == np.array(answers)\n",
    "print('accuracy:', correct_ones.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.041273584905660375\n"
     ]
    }
   ],
   "source": [
    "# 3-shot\n",
    "questions, answers = zip(*with_n_shot(test_set, n=3))\n",
    "\n",
    "outputs = model.generate_text(questions, max_length=20, stop_string='\\n')\n",
    "\n",
    "correct_ones = np.array(outputs) == np.array(answers)\n",
    "print('accuracy:', correct_ones.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.021660649819494584\n"
     ]
    }
   ],
   "source": [
    "# 20-shot\n",
    "questions, answers = zip(*with_n_shot(test_set, n=20))\n",
    "\n",
    "outputs = model.generate_text(questions, max_length=20, stop_string='\\n')\n",
    "\n",
    "correct_ones = np.array(outputs) == np.array(answers)\n",
    "print('accuracy:', correct_ones.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning Curie on the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "stop_sequence = '\\n'\n",
    "\n",
    "# clear file\n",
    "with open('dataset-algo.jsonl', 'w') as f: pass\n",
    "\n",
    "with open('dataset-algo.jsonl', 'a') as f:\n",
    "    f.writelines(json.dumps({'prompt': x, 'completion': y + stop_sequence}) + '\\n' for x, y in train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|███████████████████████| 328k/328k [00:00<00:00, 180Mit/s]\n",
      "Uploaded file from dataset-algo.jsonl: file-bzimJiRU3i7oP5bm8cJhM6FC\n",
      "Created fine-tune: ft-rvSgR5Kg436xNsAGu1fGK67D\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2022-11-26 02:18:34] Created fine-tune: ft-rvSgR5Kg436xNsAGu1fGK67D\n",
      "[2022-11-26 02:18:41] Fine-tune costs $1.20\n",
      "[2022-11-26 02:18:42] Fine-tune enqueued. Queue number: 0\n",
      "[2022-11-26 02:18:43] Fine-tune started\n",
      "\n",
      "Stream interrupted (client disconnected).\n",
      "To resume the stream, run:\n",
      "\n",
      "  openai api fine_tunes.follow -i ft-rvSgR5Kg436xNsAGu1fGK67D\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run finetuning using openai CLI\n",
    "\n",
    "!openai api fine_tunes.create -t dataset-algo.jsonl -m curie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating fine-tuned Curie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"created_at\": 1669419491,\n",
      "      \"fine_tuned_model\": \"curie:ft-university-of-tartu-2022-11-25-23-59-58\",\n",
      "      \"hyperparams\": {\n",
      "        \"batch_size\": 8,\n",
      "        \"learning_rate_multiplier\": 0.1,\n",
      "        \"n_epochs\": 4,\n",
      "        \"prompt_loss_weight\": 0.01\n",
      "      },\n",
      "      \"id\": \"ft-XtjdqmRTxlxAgqqZubqaMhWZ\",\n",
      "      \"model\": \"curie\",\n",
      "      \"object\": \"fine-tune\",\n",
      "      \"organization_id\": \"org-U4Xje8KdPBHxjYb62oL10QeW\",\n",
      "      \"result_files\": [\n",
      "        {\n",
      "          \"bytes\": 108026,\n",
      "          \"created_at\": 1669420799,\n",
      "          \"filename\": \"compiled_results.csv\",\n",
      "          \"id\": \"file-HMlO2OoPaR2PYbfeAypoMXXh\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune-results\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"status\": \"succeeded\",\n",
      "      \"training_files\": [\n",
      "        {\n",
      "          \"bytes\": 256000,\n",
      "          \"created_at\": 1669419490,\n",
      "          \"filename\": \"dataset-algo.jsonl\",\n",
      "          \"id\": \"file-UkpD6ZXE95tymyrVIVryomVb\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"updated_at\": 1669420799,\n",
      "      \"validation_files\": []\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1669421914,\n",
      "      \"fine_tuned_model\": \"curie:ft-university-of-tartu-2022-11-26-00-36-11\",\n",
      "      \"hyperparams\": {\n",
      "        \"batch_size\": 8,\n",
      "        \"learning_rate_multiplier\": 0.1,\n",
      "        \"n_epochs\": 4,\n",
      "        \"prompt_loss_weight\": 0.01\n",
      "      },\n",
      "      \"id\": \"ft-rvSgR5Kg436xNsAGu1fGK67D\",\n",
      "      \"model\": \"curie\",\n",
      "      \"object\": \"fine-tune\",\n",
      "      \"organization_id\": \"org-U4Xje8KdPBHxjYb62oL10QeW\",\n",
      "      \"result_files\": [\n",
      "        {\n",
      "          \"bytes\": 92470,\n",
      "          \"created_at\": 1669422972,\n",
      "          \"filename\": \"compiled_results.csv\",\n",
      "          \"id\": \"file-YEiGBFdKyvCDPcaS1Nu9vkbt\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune-results\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"status\": \"succeeded\",\n",
      "      \"training_files\": [\n",
      "        {\n",
      "          \"bytes\": 328000,\n",
      "          \"created_at\": 1669421913,\n",
      "          \"filename\": \"dataset-algo.jsonl\",\n",
      "          \"id\": \"file-bzimJiRU3i7oP5bm8cJhM6FC\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"updated_at\": 1669422972,\n",
      "      \"validation_files\": []\n",
      "    }\n",
      "  ],\n",
      "  \"object\": \"list\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine-tuned accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = OpenAIGPT3('curie:ft-university-of-tartu-2022-11-26-00-36-11')\n",
    "\n",
    "questions, answers = zip(*test_set)\n",
    "\n",
    "outputs = model.generate_text(questions, max_length=20, stop_string='\\n')\n",
    "\n",
    "correct_ones = np.array(outputs) == np.array(answers)\n",
    "print('fine-tuned accuracy:', correct_ones.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "\n",
    "Model: Curie\n",
    "\n",
    "Task: 2-digit XOR in binary\n",
    "\n",
    "| Zero-shot | 1-shot | 3-shot | 20-shot | Fine-tuned |\n",
    "|-----------|--------|--------|---------|------------|\n",
    "| 0%        | 1.1%   | 4.1%   | 2.2%    | 100%       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('alm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4577d946cf2b8db8046d057f010e5323d1f371d9080c229a20d8adddd315af4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
