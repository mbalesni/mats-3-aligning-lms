{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Local notebook\n",
        "\n",
        "This notebook uses functions defined elsewhere in our codebase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6K9l4VSIZnl"
      },
      "source": [
        "## BIG-Bench Metrics\n",
        "\n",
        "Each task can support multiple metrics, but has one preferred metric, used for aggregate scores. The full list of available metrics for JSON tasks can be found on the [BIG-bench repo](https://github.com/google/BIG-bench/blob/main/docs/doc.md#available-metrics). Programmatic tasks can define their own metrics. The main JSON metrics are:\n",
        "\n",
        "Text-to-text:\n",
        "- `exact_string_match`\n",
        "- `bleu`\n",
        "- `bleurt`: uses BERT to judge similarity\n",
        "- `rouge`\n",
        "\n",
        "Multiple-choice:\n",
        "- `multiple_choice_grade`: A weighted multiple choice accuracy between 0-100, where a set of\n",
        "targets and scores for each potential target are specified. This reduces to standard multiple\n",
        "choice accuracy when a single target is assigned a score of 1 and the rest score 0.\n",
        "- `expected_calibration_error`: A measure of a model’s calibration – i.e. how well the model’s\n",
        "accuracy matches the probability it assigns to a response. expected_calibration_error is the\n",
        "absolute deviation between the assigned probability and average accuracy, after binning\n",
        "examples in terms of assigned probability (Naeini et al., 2015).\n",
        "- `multiple_choice_brier_score`: A measure of calibration given as the squared error between\n",
        "model assigned probabilities and 0, 1 targets across classes (Brier, 1950)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aNI-wwOV4Hv"
      },
      "source": [
        "## Running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bigbench'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mopenai_bb\u001b[39;00m \u001b[39mimport\u001b[39;00m evaluate_on_task\n",
            "File \u001b[0;32m~/code/mats-3-aligning-lms/src/openai_bb.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbigbench\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_utils\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmodel_utils\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbigbench\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mjson_task\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mjson_task\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbigbench\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mresults\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mresults_api\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bigbench'"
          ]
        }
      ],
      "source": [
        "from src.openai_bb import evaluate_on_task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxzKRLDAVaE-",
        "outputId": "a684ba7c-5606-4366-c909-a4d092f47495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "evaluating text-curie-001...\n",
            "evaluating analytic_entailment for 3 shots...\n",
            "results:\n",
            "{'calibration_multiple_choice_brier_score': 0.49853687789680134,\n",
            " 'expected_calibration_error': 0.49579620574939887,\n",
            " 'multiple_choice_grade': 0.4857142857142857,\n",
            " 'normalized_aggregate_score': -2.857142857142858}\n"
          ]
        }
      ],
      "source": [
        "results_data = evaluate_on_task(task_name='analytic_entailment', model_name='text-curie-001', shots_list=[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2SGHi3HVnCx",
        "outputId": "f7b8e3af-3082-4ca2-ef92-8db888b4cc61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "evaluating text-curie-001...\n",
            "evaluating emoji_movie for 3 shots...\n",
            "results:\n",
            "{'bleu': 10.839884430478508,\n",
            " 'calibration_multiple_choice_brier_score': 0.22352366663024548,\n",
            " 'exact_str_match': 0.08,\n",
            " 'expected_calibration_error': 0.4583487377784708,\n",
            " 'multiple_choice_grade': 0.2,\n",
            " 'normalized_aggregate_score': 4.857225732735058e-14,\n",
            " 'rouge1': 19.274314574314577,\n",
            " 'rouge2': 11.933333333333332,\n",
            " 'rougeLsum': 19.346176046176044}\n"
          ]
        }
      ],
      "source": [
        "results_data = evaluate_on_task(task_name='emoji_movie', model_name='text-curie-001', shots_list=[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMHVzNszcIef",
        "outputId": "5f375838-5f6e-4eb3-90d7-28b663ecbf5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "evaluating ada...\n",
            "results:\n",
            "{'first_response_score': -0.97,\n",
            " 'full': -0.954387807683251,\n",
            " 'second_response_score': 0.015612192316749042}\n",
            "{'first_response_score': -0.97,\n",
            " 'full': -0.954387807683251,\n",
            " 'normalized_aggregate_score': 67.42686987194583,\n",
            " 'second_response_score': 0.015612192316749042}\n"
          ]
        }
      ],
      "source": [
        "results_data = evaluate_on_task(task_name='taboo', model_name='ada', shots_list=[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TvH9yLGdQ_1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.15 ('alm')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "085c9e41704d079f0036212aafa0f1dcb6ec70aaa977df83d62015b7798a3be1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
